{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a095dd-a489-4c89-82ca-100df11c47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c673795-c57a-48a4-b1ba-97f92019de44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U accelerate\n",
    "# !pip install -U transformers\n",
    "# !pip install openai==0.28\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c817ac-54d2-4014-9fff-e40f70036639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import subprocess\n",
    "# from huggingface_hub import hf_hub_download\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "#from google.colab import drive\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9262ccb3-3883-4fa0-998e-1018e3988f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_TOKEN\"] = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "# env_vars = os.environ\n",
    "# for key, value in env_vars.items():\n",
    "#     print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eeab655-593b-4bc5-88d6-b98930fc8477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "682f77d5-4812-4852-b25a-1683f1af3098",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8237ab5e-4649-4cd7-bc77-563d64efc4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"nguha/legalbench\", 'cuad_audit_rights', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31f75ffe-0661-4e18-af56-ee79c88ae22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'index', 'text', 'document_name'],\n",
       "        num_rows: 6\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'index', 'text', 'document_name'],\n",
       "        num_rows: 1216\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca6e0788-4a87-4ad3-875d-f2e3161b6030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (977, 5)\n",
      "Validation set size: (147, 5)\n",
      "Test set size: (98, 5)\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame for easier handling\n",
    "df_train = pd.DataFrame(dataset['test'])\n",
    "df_test = pd.DataFrame(dataset['train'])\n",
    "\n",
    "# Preprocess text\n",
    "df_train['cleaned_text'] = df_train['text'].apply(lambda text: text.strip().lower())\n",
    "df_test['cleaned_text'] = df_test['text'].apply(lambda text: text.strip().lower())\n",
    "\n",
    "#To split the data better\n",
    "df_combined = pd.concat([df_train, df_test])\n",
    "df_combined.drop(columns=['index'])\n",
    "\n",
    "# Shuffle the data\n",
    "df_combined_shuffled = df_combined.sample(frac=1).reset_index(drop=True)\n",
    "df_combined_shuffled.drop(columns=['index'])\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_data, test_data = train_test_split(df_combined_shuffled, test_size=0.2, stratify = df_combined_shuffled['answer'])\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.4, stratify = test_data['answer'])\n",
    "\n",
    "print(f\"Training set size: {train_data.shape}\")\n",
    "print(f\"Validation set size: {val_data.shape}\")\n",
    "print(f\"Test set size: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3181dd0e-c758-48eb-be1e-2268b1d107f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('nlpaueb/legal-bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('nlpaueb/legal-bert-base-uncased', num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# Tokenize the inputs\n",
    "train_encodings = tokenizer(train_data['cleaned_text'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_data['cleaned_text'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Convert labels to tensor\n",
    "train_labels = torch.tensor(train_data['answer'].apply(lambda x: 1 if x.lower() == \"yes\" else 0).tolist())\n",
    "val_labels = torch.tensor(val_data['answer'].apply(lambda x: 1 if x.lower() == \"yes\" else 0).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7bfb20b-ed70-46af-a039-ccd47ba523bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset class\n",
    "class LegalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = LegalDataset(train_encodings, train_labels)\n",
    "val_dataset = LegalDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c4004f6-e928-4ef3-a9ca-d1d30e5aa453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_texts, train_labels, val_texts, val_labels, model, tokenizer):\n",
    "\n",
    "    # Tokenize the inputs\n",
    "    train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=512)\n",
    "    val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "    # Convert labels to tensor\n",
    "    train_labels = torch.tensor(train_labels.apply(lambda x: 1 if x.lower() == \"yes\" else 0).tolist())\n",
    "    val_labels = torch.tensor(val_labels.apply(lambda x: 1 if x.lower() == \"yes\" else 0).tolist())\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = LegalDataset(train_encodings, train_labels)\n",
    "    val_dataset = LegalDataset(val_encodings, val_labels)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='/results',\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        eval_strategy=\"epoch\"\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model = model,\n",
    "        args = training_args,\n",
    "        train_dataset = train_dataset,\n",
    "        eval_dataset = val_dataset,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    predictions = trainer.predict(val_dataset)\n",
    "    preds = predictions.predictions.argmax(-1)\n",
    "    labels = predictions.label_ids\n",
    "\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a599bcd-8189-411e-b428-8dfd5dd60d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='468' max='468' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [468/468 13:01:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.112900</td>\n",
       "      <td>0.115321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.231900</td>\n",
       "      <td>0.081328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.030517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='468' max='468' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [468/468 3:04:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.023682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.001537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [471/471 3:10:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.108400</td>\n",
       "      <td>0.013612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.112874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.091538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='468' max='468' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [468/468 3:19:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.103300</td>\n",
       "      <td>0.069218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.071755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.145785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='477' max='477' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [477/477 3:27:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.046897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.161640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.227348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.9832269069518975\n",
      "Average Precision: 0.9796253273141206\n",
      "Average Recall: 0.9872941176470589\n",
      "Average F1 Score: 0.9832096174486324\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# We used k-fold cross-validation to ensure that the model's performance is robust and generalizable.\n",
    "# K-fold cross-validation splits the data into 'k' subsets, trains the model on 'k-1' subsets, and validates it on the remaining subset.\n",
    "# This process is repeated 'k' times with different subsets as the validation set each time.\n",
    "# By averaging the results, we get a more reliable estimate of the model's performance and reduce the risk of overfitting,\n",
    "# as the model is validated on different data segments in each fold.\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "accuracies, precisions, recalls, f1s = [], [], [], []\n",
    "texts = train_data['cleaned_text']\n",
    "labels = train_data['answer']\n",
    "i=0\n",
    "for train_index, val_index in kf.split(texts, labels):\n",
    "    train_texts = texts[texts.index.isin(train_index)]\n",
    "    val_texts = texts[texts.index.isin(val_index)]\n",
    "    train_labels = labels[labels.index.isin(train_index)]\n",
    "    val_labels = labels[labels.index.isin(val_index)]\n",
    "\n",
    "    #Initializing a new model\n",
    "    model = BertForSequenceClassification.from_pretrained('nlpaueb/legal-bert-base-uncased', num_labels=2)\n",
    "    tokenizer = BertTokenizer.from_pretrained('nlpaueb/legal-bert-base-uncased')\n",
    "    model.to(device)\n",
    "\n",
    "    accuracy, precision, recall, f1 = train_and_evaluate(train_texts, train_labels, val_texts, val_labels, model, tokenizer)\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)\n",
    "\n",
    "    model.save_pretrained('fine-tuned-legal-bert-fold'+str(i))\n",
    "    tokenizer.save_pretrained('fine-tuned-legal-bert-fold'+str(i))\n",
    "    i+=1\n",
    "\n",
    "# Print average metrics\n",
    "print(f\"Average Accuracy: {sum(accuracies) / len(accuracies)}\")\n",
    "print(f\"Average Precision: {sum(precisions) / len(precisions)}\")\n",
    "print(f\"Average Recall: {sum(recalls) / len(recalls)}\")\n",
    "print(f\"Average F1 Score: {sum(f1s) / len(f1s)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9e0e408-3e14-473e-9866-5b8423b22010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test function\n",
    "def test_model(test_texts, test_labels, model_path, tokenizer_path):\n",
    "    # Load the fine-tuned model and tokenizer\n",
    "    model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "    tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "    model.to(device)\n",
    "\n",
    "    # Tokenize the test texts\n",
    "    test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "    # Convert labels to tensor\n",
    "    test_labels_tensor = torch.tensor(test_labels.apply(lambda x: 1 if x.lower() == \"yes\" else 0).tolist())\n",
    "\n",
    "    # Create a test dataset\n",
    "    test_dataset = LegalDataset(test_encodings, test_labels_tensor)\n",
    "\n",
    "    # Create a DataLoader for the test dataset\n",
    "    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels.extend(batch['labels'].cpu().numpy())\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            preds.extend(torch.argmax(outputs.logits, dim=-1).cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ebc508d-89bc-480c-8fee-0b68a671c9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 - Accuracy: 0.9897959183673469, Precision: 0.98, Recall: 1.0, F1 Score: 0.98989898989899\n",
      "Model 1 - Accuracy: 1.0, Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
      "Model 2 - Accuracy: 0.9183673469387755, Precision: 1.0, Recall: 0.8367346938775511, F1 Score: 0.9111111111111111\n",
      "Model 3 - Accuracy: 0.9591836734693877, Precision: 0.9591836734693877, Recall: 0.9591836734693877, F1 Score: 0.9591836734693877\n",
      "Model 4 - Accuracy: 0.9693877551020408, Precision: 0.9423076923076923, Recall: 1.0, F1 Score: 0.9702970297029703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model (untrained Legal-BERT) - Accuracy: 0.5, Precision: 0.5, Recall: 0.02040816326530612, F1 Score: 0.0392156862745098\n"
     ]
    }
   ],
   "source": [
    "# Load your test data\n",
    "test_texts = test_data['cleaned_text']\n",
    "test_labels = test_data['answer']\n",
    "\n",
    "# Iterate over the saved models and evaluate them\n",
    "for i in range(5):  # Assuming you have 5 models\n",
    "    model_path = f'fine-tuned-legal-bert-fold{i}'\n",
    "    tokenizer_path = f'fine-tuned-legal-bert-fold{i}'\n",
    "\n",
    "    accuracy, precision, recall, f1 = test_model(test_texts, test_labels, model_path, tokenizer_path)\n",
    "    print(f\"Model {i} - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n",
    "\n",
    "accuracy, precision, recall, f1 = test_model(test_texts, test_labels,'nlpaueb/legal-bert-base-uncased', 'nlpaueb/legal-bert-base-uncased')\n",
    "print(f\"Model (untrained Legal-BERT) - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "898d0b20-e683-47fe-9195-98436fa399c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model = BertForSequenceClassification.from_pretrained(\"C:\\\\Users\\\\soria\\\\Desktop\\\\fine-tuned-legal-bert-fold1\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"C:\\\\Users\\\\soria\\\\Desktop\\\\fine-tuned-legal-bert-fold1\")\n",
    "model.to(device)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57adde2b-8782-4817-9623-86200c994159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Function for classification using Legal-BERT\n",
    "def classify_clause_legal_bert(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    return predictions.item()\n",
    "\n",
    "# Define a test clause\n",
    "test_clause = \"Each party shall cause any subsidiary or other affiliate (including, without limitation, a subsidiary or other affiliate of the online group or skype group, as applicable) to grant to the other party the audit rights granted hereunder with respect to such other party.\"\n",
    "\n",
    "# Get the combined result\n",
    "response = classify_clause_legal_bert(test_clause)\n",
    "\n",
    "# Print the combined result\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d796cd52-8379-4d38-a24a-f398f4ccba9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4-turbo\n",
      "gpt-4-turbo-2024-04-09\n",
      "tts-1\n",
      "tts-1-1106\n",
      "chatgpt-4o-latest\n",
      "dall-e-2\n",
      "gpt-4-turbo-preview\n",
      "gpt-4o-mini\n",
      "gpt-4o-mini-2024-07-18\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-4-0125-preview\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-3.5-turbo\n",
      "babbage-002\n",
      "davinci-002\n",
      "gpt-4o-realtime-preview-2024-10-01\n",
      "dall-e-3\n",
      "gpt-4o-realtime-preview\n",
      "gpt-4o-2024-05-13\n",
      "tts-1-hd\n",
      "gpt-4o\n",
      "tts-1-hd-1106\n",
      "gpt-4-1106-preview\n",
      "text-embedding-ada-002\n",
      "gpt-3.5-turbo-16k\n",
      "text-embedding-3-small\n",
      "gpt-4o-2024-08-06\n",
      "text-embedding-3-large\n",
      "whisper-1\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-4-0613\n",
      "gpt-4\n",
      "gpt-3.5-turbo-instruct-0914\n"
     ]
    }
   ],
   "source": [
    "# Set up OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Get the list of models available\n",
    "models_available = openai.Model.list()\n",
    "\n",
    "# Loop through and print the model IDs\n",
    "for model in models_available['data']:\n",
    "    print(model['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "58737784-fc7b-4034-a787-224ac5d7620d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The clause presented contains several potential risks that could arise during its execution:\n",
      "\n",
      "1. **Scope of Affiliates**: The clause seems to broadly include subsidiaries and other affiliates, potentially even those that are not directly relevant to the contract. This broad scope could lead to practical difficulties and disagreements about which entities are included. Further clarification and limitation might be necessary to avoid confusion and ensure compliance.\n",
      "\n",
      "2. **Control Over Affiliates**: Parties may not have sufficient control over their affiliates to enforce such obligations effectively. Not all affiliates may be willing or able to comply with the audit requirements, which could lead to breaches of the agreement and potential legal disputes.\n",
      "\n",
      "3. **Confidentiality and Privacy Concerns**: Auditing rights might lead to exposure of sensitive, confidential, or proprietary information of subsidiaries or affiliates. There must be safeguards such as Non-Disclosure Agreements (NDAs) to protect privacy and proprietary information during audits.\n",
      "\n",
      "4. **Legal Restrictions**: Affiliates operating in different jurisdictions may be subject to local laws that restrict external audits or sharing of information with third parties. This could create legal complications and risks of non-compliance with local laws and regulations.\n",
      "\n",
      "5. **Operational Burden**: Granting audit rights can impose significant operational and financial burdens on subsidiaries or affiliates, particularly if multiple parties request audits. This could strain resources or divert attention from core operations.\n",
      "\n",
      "6. **Vague Terminology**: Terms like \"other party\" and \"audit rights granted hereunder\" are somewhat vague and can lead to differing interpretations. Defining these terms with precision is crucial to prevent misunderstandings and disputes over the clause’s intention and extent.\n",
      "\n",
      "7. **Liability Issues**: If a subsidiary or affiliate fails to comply with the audit requirements, it is unclear how liability will be apportioned. Clear provisions need to be established for the allocation of responsibility and potential penalties for non-compliance.\n",
      "\n",
      "To mitigate these risks, it's advisable to clarify the clause's terms, possibly limit the scope of affiliates affected, and ensure compliance with all applicable legal requirements. Additionally, obtaining explicit commitments from affiliates and incorporating safeguard measures could strengthen the enforceability and effectiveness of the clause.\n"
     ]
    }
   ],
   "source": [
    "def run_riskAnalysis(clause):\n",
    "    # Risk Analysis using GPT-4o\n",
    "    risk_template = \"You are a legal advisor. Identify any potential risks in the clauses given to you.\"\n",
    "    prompt = clause\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": risk_template},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Define a test clause\n",
    "test_clause = \"Each party shall cause any subsidiary or other affiliate (including, without limitation, a subsidiary or other affiliate of the online group or skype group, as applicable) to grant to the other party the audit rights granted hereunder with respect to such other party.\"\n",
    "\n",
    "# Get the combined result\n",
    "response = run_riskAnalysis(test_clause)\n",
    "\n",
    "# Print the combined result\n",
    "print(response)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c14ff023-a866-46ee-9ab3-758eb7db46e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the prompt using the ChatCompletion endpoint\n",
    "def run_gpt_integration(classification_label, risk_analysis, clause):\n",
    "    prompt = (\n",
    "        f\"Here is a contract clause that has been classified as '{classification_label}':\\n\\n\"\n",
    "        f\"'{clause}'\\n\\n\"\n",
    "        f\"The potential risks identified in this clause are:\\n{risk_analysis}\\n\\n\"\n",
    "    )\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a legal advisor. Please provide an integrated, cohesive explanation of this clause, its classification, and the identified risks. Provide the respone in the following template:\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e7e1ff0a-67d4-43e3-b4c7-9b4fdfcc20f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Clause Explanation:**\n",
      "\n",
      "The presented clause is an \"Audit Clause,\" focusing on granting audit rights between contracting parties and their respective subsidiaries or affiliates. The clause mandates that each party ensure their subsidiaries or affiliates provide similar audit rights as those stated in the contract, without limiting those rights to specific terms or conditions.\n",
      "\n",
      "**Clause Classification:**\n",
      "\n",
      "The clause is classified as an 'Audit Clause' because it pertains to the right to examine, verify, and ensure compliance with contractual obligations by one party upon another's subsidiaries or affiliates. It potentially involves financial, procedural, or operational inspections, as allowed by the broader scope of the agreement.\n",
      "\n",
      "**Identified Risks and Explanations:**\n",
      "\n",
      "1. **Ambiguity and Broad Scope**: This clause lacks specificity in defining the exact audit rights, which could result in differing interpretations and conflicts over its implementation. A dispute might arise if one party believes the audit extends beyond a reasonable or expected domain.\n",
      "\n",
      "2. **Control Over Affiliates**: The assumption that a party can command its affiliates, which could be separate legal entities, to concede to audit rights can be problematic. This is especially true if an affiliate operates independently or internationally, having its own governance.\n",
      "\n",
      "3. **Privacy and Data Protection Concerns**: Audits often require access to data that could include personal or sensitive information. If data protection laws applicable to affiliates don't align with the audit's requirement, it might result in violations of privacy regulations.\n",
      "\n",
      "4. **Confidentiality Issues**: Conducting audits may inadvertently result in disclosing confidential business strategies or sensitive data. There’s a risk of such information being mishandled or disclosed, lacking adequate confidentiality protocols within the audit process.\n",
      "\n",
      "5. **Compliance and Regulatory Risks**: Affiliates might be subject to regulations specific to their jurisdictions, differing significantly from those of the contracting parties. The clause needs to accommodate varying legal obligations to prevent accidental non-compliance and potential legal penalties.\n",
      "\n",
      "6. **Potential Liability**: If an affiliate is non-compliant with the audit requirements, the principal party could unjustly face legal responsibility or breach claims over actions they didn't directly control, especially if the affiliate's governance is autonomous.\n",
      "\n",
      "7. **Conflict Between Entities**: Imposing this obligation might strain relationships between a parent company and its affiliates, particularly if the affiliates view the audit rights as intrusive or infringing on their autonomy.\n",
      "\n",
      "8. **Cost and Resource Implications**: Executing audit rights across multiple subsidiaries or affiliates can be resource-demanding, incurring significant financial costs and operational burdens, often not justified without a detailed, predefined scope and necessity.\n",
      "\n",
      "**Recommendations:**\n",
      "\n",
      "To mitigate these risks, it’s advisable to:\n",
      "\n",
      "- Clearly define the scope and procedures of audit rights.\n",
      "- Ensure compliance with privacy and data protection laws across jurisdictions.\n",
      "- Implement robust confidentiality measures.\n",
      "- Address potential liabilities and responsibilities explicitly.\n",
      "- Limit audit rights to essential areas pertinent to the contract.\n",
      "- Set clear protocols for audits concerning conflict resolution and cost sharing.\n"
     ]
    }
   ],
   "source": [
    "# Define a combined function\n",
    "def classify_and_analyze_clause(clause):\n",
    "    classification_result = classify_clause_legal_bert(clause)\n",
    "    classification_label = \"Audit Clause\" if classification_result == 1 else \"Not an Audit Clause\"\n",
    "    risk_analysis = run_riskAnalysis(clause)\n",
    "    integrated_response = run_gpt_integration(classification_label, risk_analysis, clause)\n",
    "    return integrated_response\n",
    "\n",
    "# Define a test clause\n",
    "test_clause = \"Each party shall cause any subsidiary or other affiliate (including, without limitation, a subsidiary or other affiliate of the online group or skype group, as applicable) to grant to the other party the audit rights granted hereunder with respect to such other party.\"\n",
    "\n",
    "# Get the combined result\n",
    "response = classify_and_analyze_clause(test_clause)\n",
    "\n",
    "# Print the combined result\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5562fcaf-5729-4e21-bb72-234d1fa87f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Explanation of the Clause:\n",
      "\n",
      "The given contract clause is classified as an \"Audit Clause\". It requires each party involved in the contract to ensure that their subsidiaries or affiliates grant the other party the same audit rights as those outlined in the contract. Essentially, this clause aims to extend the audit rights from the primary parties involved to include their respective subsidiaries and affiliates, ensuring a wider scope for auditing.\n",
      "\n",
      "### Classification:\n",
      "\n",
      "This is an \"Audit Clause,\" which typically outlines the rights and procedures by which one party can inspect, verify, or review the accounts, operations, processes, or records of the other party. Such clauses are used in contracts to ensure transparency, compliance, and accountability, often in financial, data handling, or compliance contexts.\n",
      "\n",
      "### Identified Risks:\n",
      "\n",
      "1. **Lack of Specificity**: The clause does not clearly define the scope and limitations of the audit rights. Without clear boundaries, this could lead to disputes over what can be audited and how audits should be conducted. Resolution involves explicitly outlining the scope, purpose, frequency, and method of audits.\n",
      "\n",
      "2. **Privacy Concerns**: Granting extensive audit rights can lead to privacy issues, especially if personal or sensitive data is involved. It is important to ensure compliance with relevant data protection regulations such as GDPR or CCPA to prevent unauthorized access to data.\n",
      "\n",
      "3. **Third-Party Agreements**: Subsidiaries or affiliates might be governed by their own agreements, which could conflict with the audit rights granted in this clause. This could require renegotiating these agreements or stipulating conditions under which audit rights can be exercised.\n",
      "\n",
      "4. **Control and Influence**: The clause presupposes that parties have sufficient control over their subsidiaries and affiliates to impose these requirements. This may not be feasible if these entities are independently governed, necessitating legal assessments of control structures.\n",
      "\n",
      "5. **Liability for Non-Compliance**: There is no clarification about who would be liable if a subsidiary or affiliate does not comply with audit requirements. The clause should specify whether the primary contracting party will bear responsibility for any non-compliance.\n",
      "\n",
      "6. **Potential Resistance**: Subsidiaries or affiliates may resist audits due to concerns over confidentiality, competitive sensitivity, or administrative burdens. This resistance could lead to compliance challenges and needs addressing by aligning such audits with existing policies or agreements.\n",
      "\n",
      "7. **Reciprocity and Balance**: For fairness, the clause should confer similar rights and obligations on both parties. Lack of balance could lead to disputes or perceived inequalities in contractual obligations.\n",
      "\n",
      "8. **Temporal Limits**: The clause does not specify the duration of the audit rights, potentially leading to indefinite obligations. This requires defining timeframes to align with corporate planning and policy requirements.\n",
      "\n",
      "9. **Legal and Regulatory Compliance**: Extending audit rights may conflict with legal or regulatory mandates in different jurisdictions where subsidiaries or affiliates operate. The clause must be reviewed against applicable laws to avoid violations.\n",
      "\n",
      "### Advisory:\n",
      "\n",
      "To mitigate these risks, it is advisable to redraft the clause with detailed provisions that outline the specific scope of audit rights, compliance with privacy laws, recognition of third-party agreements, and a clear delineation of liabilities. Furthermore, consulting with legal counsel, especially those with international expertise if applicable, will ensure that the clause is compliant and equitable, while safeguarding the interests of all parties involved.\n"
     ]
    }
   ],
   "source": [
    "# Combined function to classify and analyze a clause\n",
    "def classify_and_analyze_clause(clause):\n",
    "    try:\n",
    "        # Classify the clause\n",
    "        classification_result = classify_clause_legal_bert(clause)\n",
    "        classification_label = \"Audit Clause\" if classification_result == 1 else \"Not an Audit Clause\"\n",
    "        \n",
    "        # Perform risk analysis\n",
    "        risk_analysis = run_riskAnalysis(clause)\n",
    "        \n",
    "        # Generate an integrated response\n",
    "        integrated_response = run_gpt_integration(classification_label, risk_analysis, clause)\n",
    "        \n",
    "        return integrated_response\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# Test clause to classify and analyze\n",
    "test_clause = \"Each party shall cause any subsidiary or other affiliate (including, without limitation, a subsidiary or other affiliate of the online group or skype group, as applicable) to grant to the other party the audit rights granted hereunder with respect to such other party.\"\n",
    "\n",
    "# Get and print the combined result\n",
    "response = classify_and_analyze_clause(test_clause)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8322a3-a860-4db9-95c9-f681bd45eeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
